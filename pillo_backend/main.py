from fastapi import FastAPI, HTTPException
from fastapi.middleware.cors import CORSMiddleware
from fastapi.responses import StreamingResponse
from pydantic import BaseModel
import cv2
import numpy as np
import asyncio
import threading
import time
from datetime import datetime
import uvicorn
import io
import base64
from typing import Optional

try:
    from ultralytics import YOLO
except Exception:
    YOLO = None

app = FastAPI(title="è¼ªå»“åµæ¸¬ API", version="1.0.0")

# å…è¨±è·¨åŸŸè«‹æ±‚
app.add_middleware(
    CORSMiddleware,
    allow_origins=["*"],  # åœ¨ç”Ÿç”¢ç’°å¢ƒä¸­æ‡‰è©²é™åˆ¶å…·é«”åŸŸå
    allow_credentials=True,
    allow_methods=["*"],
    allow_headers=["*"],
)

# è«‹æ±‚æ¨¡å‹
class AlgorithmRequest(BaseModel):
    algorithm: str

class CameraController:
    def __init__(self):
        self.cap = None
        self.is_streaming = False
        self.detection_active = False
        self.current_count = 0
        self.algorithm = "algorithm2"
        self.latest_frame = None
        self.frame_lock = threading.Lock()
        self.yolo_model: Optional["YOLO"] = None
        
    def start_camera(self, camera_index=0):
        try:
            # å˜—è©¦ä¸åŒçš„æ”å½±æ©Ÿç´¢å¼•
            camera_indices = [camera_index, 0, 1, 2, 3]
            for idx in camera_indices:
                self.cap = cv2.VideoCapture(idx)
                if self.cap.isOpened():
                    break
                    
            if not self.cap.isOpened():
                return False, "ç„¡æ³•é–‹å•Ÿä»»ä½•æ”å½±æ©Ÿ"
                
            # è¨­å®šæ”å½±æ©Ÿåƒæ•¸
            # è¨­å®š 30 FPS èˆ‡è§£æåº¦
            self.cap.set(cv2.CAP_PROP_FRAME_WIDTH, 640)
            self.cap.set(cv2.CAP_PROP_FRAME_HEIGHT, 360)
            self.cap.set(cv2.CAP_PROP_FPS, 30)
            # æ¸›å°‘å…§éƒ¨ç·©è¡é¿å…å»¶é²ç´¯ç©ï¼ˆè‹¥ç›¸æ©Ÿé©…å‹•æ”¯æ´ï¼‰
            try:
                self.cap.set(cv2.CAP_PROP_BUFFERSIZE, 1)
            except Exception:
                pass
            
            self.is_streaming = True
            
            # å•Ÿå‹•æ”å½±æ©ŸåŸ·è¡Œç·’
            self.camera_thread = threading.Thread(target=self._camera_loop, daemon=True)
            self.camera_thread.start()
            
            return True, "æ”å½±æ©Ÿå•Ÿå‹•æˆåŠŸ"
        except Exception as e:
            return False, f"æ”å½±æ©Ÿå•Ÿå‹•å¤±æ•—: {str(e)}"
    
    def _camera_loop(self):
        """æ”å½±æ©Ÿä¸»å¾ªç’°"""
        while self.is_streaming and self.cap:
            ret, frame = self.cap.read()
            if not ret:
                continue
                
            display_frame = frame.copy()
            
            if self.detection_active:
                try:
                    if self.algorithm == "yolo11":
                        count = self.process_yolo(frame, display_frame)
                    else:
                        count = self.process_contours(frame, display_frame)
                    self.current_count = count
                except Exception as e:
                    print(f"è™•ç†éŒ¯èª¤: {e}")
                    self.current_count = 0
            else:
                self.current_count = 0
                
            # æ›´æ–°æœ€æ–°å¹€
            with self.frame_lock:
                self.latest_frame = display_frame.copy()
                
            # æ§åˆ¶å¹€ç‡ï¼ˆ30 FPSï¼‰
            time.sleep(1/30)
    
    def stop_camera(self):
        self.is_streaming = False
        self.detection_active = False
        if self.cap:
            self.cap.release()
            self.cap = None
        with self.frame_lock:
            self.latest_frame = None
        return True, "æ”å½±æ©Ÿå·²åœæ­¢"
    
    def get_frame_as_base64(self):
        """ç²å–ç•¶å‰å¹€çš„ base64 ç·¨ç¢¼"""
        with self.frame_lock:
            if self.latest_frame is None:
                return None
            frame = self.latest_frame.copy()
            
        # ç·¨ç¢¼ç‚º JPEGï¼ˆé™ä½å“è³ªæ¸›å°å‚³è¼¸èˆ‡ç·¨ç¢¼è² è¼‰ï¼‰
        ret, buffer = cv2.imencode('.jpg', frame, [cv2.IMWRITE_JPEG_QUALITY, 60])
        if ret:
            # è½‰æ›ç‚º base64
            img_base64 = base64.b64encode(buffer).decode('utf-8')
            return f"data:image/jpeg;base64,{img_base64}"
        return None
    
    def process_contours(self, frame, display_frame):
        gray = cv2.cvtColor(frame, cv2.COLOR_BGR2GRAY)
        blur = cv2.GaussianBlur(gray, (7, 7), 0)
        
        if self.algorithm == "algorithm1":
            # ç®—æ³•ä¸€ï¼šOtsu äºŒå€¼åŒ–
            _, thresh = cv2.threshold(blur, 80, 255, cv2.THRESH_BINARY_INV + cv2.THRESH_OTSU)
            contours, _ = cv2.findContours(thresh, cv2.RETR_EXTERNAL, cv2.CHAIN_APPROX_SIMPLE)
        else:
            # ç®—æ³•äºŒï¼šCanny é‚Šç·£åµæ¸¬
            canny = cv2.Canny(blur, 100, 150, 3)
            dilated = cv2.dilate(canny, (1, 1), iterations=0)
            contours, _ = cv2.findContours(dilated.copy(), cv2.RETR_EXTERNAL, cv2.CHAIN_APPROX_NONE)
        
        count = len(contours)
        
        # ç•«å‡ºè¼ªå»“
        cv2.drawContours(display_frame, contours, -1, (0, 255, 0), 2)
        
        # é¡¯ç¤ºæ•¸é‡
        cv2.putText(display_frame, f"Count: {count}", (20, 50),
                   cv2.FONT_HERSHEY_SIMPLEX, 1.5, (0, 0, 255), 3, cv2.LINE_AA)
        
        return count

    def ensure_yolo_loaded(self):
        if self.yolo_model is None:
            if YOLO is None:
                raise RuntimeError("Ultralytics YOLO æœªå®‰è£ï¼Œè«‹åœ¨å¾Œç«¯å®‰è£ ultralytics å¥—ä»¶")
            # è¼‰å…¥æœ¬åœ°æ¨¡å‹æª”
            self.yolo_model = YOLO("my_model.pt")

    def process_yolo(self, frame, display_frame):
        # ç¢ºä¿æ¨¡å‹å·²è¼‰å…¥
        self.ensure_yolo_loaded()
        # BGR -> RGB
        rgb = cv2.cvtColor(frame, cv2.COLOR_BGR2RGB)
        # æ¨è«–ï¼ˆè¨­å®šè¼ƒå¿«çš„åƒæ•¸ï¼‰
        results = self.yolo_model.predict(source=rgb, verbose=False, imgsz=640, conf=0.25, iou=0.45, device=0 if cv2.cuda.getCudaEnabledDeviceCount() > 0 else 'cpu')
        # å–ç¬¬ä¸€å¼µçµæœ
        r = results[0]
        boxes = r.boxes
        count = 0
        if boxes is not None:
            for box in boxes:
                x1, y1, x2, y2 = box.xyxy[0].cpu().numpy().astype(int)
                conf = float(box.conf[0].cpu().numpy()) if box.conf is not None else 0.0
                cls_id = int(box.cls[0].cpu().numpy()) if box.cls is not None else -1
                count += 1
                # ç•«æ¡†èˆ‡æ¨™ç±¤
                cv2.rectangle(display_frame, (x1, y1), (x2, y2), (0, 255, 0), 2)
                label = f"ID{cls_id} {conf:.2f}"
                cv2.putText(display_frame, label, (x1, max(y1-5, 10)), cv2.FONT_HERSHEY_SIMPLEX, 0.6, (255, 255, 0), 2)
        # é¡¯ç¤ºæ•¸é‡
        cv2.putText(display_frame, f"YOLO Count: {count}", (20, 50), cv2.FONT_HERSHEY_SIMPLEX, 1.5, (0, 0, 255), 3, cv2.LINE_AA)
        return count

# å‰µå»ºæ”å½±æ©Ÿæ§åˆ¶å™¨å¯¦ä¾‹
camera_controller = CameraController()

@app.get("/")
async def root():
    return {"message": "è¼ªå»“åµæ¸¬ API æœå‹™é‹è¡Œä¸­"}

@app.post("/api/camera/start")
async def start_camera():
    success, message = camera_controller.start_camera()
    if success:
        return {"success": True, "message": message}
    else:
        raise HTTPException(status_code=400, detail=message)

@app.post("/api/camera/stop")
async def stop_camera():
    success, message = camera_controller.stop_camera()
    return {"success": success, "message": message}

@app.post("/api/detection/start")
async def start_detection():
    camera_controller.detection_active = True
    return {"success": True, "message": "é–‹å§‹è¼ªå»“åµæ¸¬"}

@app.post("/api/detection/stop")
async def stop_detection():
    camera_controller.detection_active = False
    return {"success": True, "message": "åœæ­¢è¼ªå»“åµæ¸¬"}

@app.post("/api/algorithm/change")
async def change_algorithm(request: AlgorithmRequest):
    camera_controller.algorithm = request.algorithm
    return {"success": True, "message": "ç®—æ³•å·²æ›´æ›"}

@app.get("/api/status")
async def get_status():
    timestamp = datetime.now().strftime('%H:%M:%S')
    return {
        "count": camera_controller.current_count,
        "timestamp": timestamp,
        "is_streaming": camera_controller.is_streaming,
        "detection_active": camera_controller.detection_active,
        "algorithm": camera_controller.algorithm
    }

@app.get("/api/video/frame")
async def get_video_frame():
    """ç²å–ç•¶å‰è¦–è¨Šå¹€"""
    frame_data = camera_controller.get_frame_as_base64()
    # å³ä½¿æš«æ™‚æ²’æœ‰å¹€ä¹Ÿå› 200 ä¸¦çµ¦äºˆ nullï¼Œé¿å…å‰ç«¯æŠŠé€£ç·šæ¨™è¨˜ç‚ºéŒ¯èª¤
    return {"frame": frame_data if frame_data else None}

if __name__ == "__main__":
    print("ğŸš€ å•Ÿå‹• FastAPI å¾Œç«¯æœå‹™")
    print("ğŸ“± API æ–‡æª”: http://localhost:8000/docs")
    print("ğŸŒ å±€åŸŸç¶²å­˜å–: http://[æ‚¨çš„IPåœ°å€]:8000")
    print("ğŸ’¡ æŒ‰ Ctrl+C åœæ­¢æœå‹™")
    
    uvicorn.run(
        "main:app", 
        host="0.0.0.0", 
        port=8000, 
        reload=True,
        log_level="info"
    )