from fastapi import FastAPI, HTTPException
from fastapi.middleware.cors import CORSMiddleware
from fastapi.responses import StreamingResponse
from pydantic import BaseModel
import cv2
import numpy as np
import asyncio
import threading
import time
from datetime import datetime
import uvicorn
import io
import base64

app = FastAPI(title="è¼ªå»“åµæ¸¬ API", version="1.0.0")

# å…è¨±è·¨åŸŸè«‹æ±‚
app.add_middleware(
    CORSMiddleware,
    allow_origins=["*"],  # åœ¨ç”Ÿç”¢ç’°å¢ƒä¸­æ‡‰è©²é™åˆ¶å…·é«”åŸŸå
    allow_credentials=True,
    allow_methods=["*"],
    allow_headers=["*"],
)

# è«‹æ±‚æ¨¡å‹
class AlgorithmRequest(BaseModel):
    algorithm: str

class CameraController:
    def __init__(self):
        self.cap = None
        self.is_streaming = False
        self.detection_active = False
        self.current_count = 0
        self.algorithm = "algorithm2"
        self.latest_frame = None
        self.frame_lock = threading.Lock()
        
    def start_camera(self, camera_index=0):
        try:
            # å˜—è©¦ä¸åŒçš„æ”å½±æ©Ÿç´¢å¼•
            camera_indices = [camera_index, 0, 1, 2, 3]
            for idx in camera_indices:
                self.cap = cv2.VideoCapture(idx)
                if self.cap.isOpened():
                    break
                    
            if not self.cap.isOpened():
                return False, "ç„¡æ³•é–‹å•Ÿä»»ä½•æ”å½±æ©Ÿ"
                
            # è¨­å®šæ”å½±æ©Ÿåƒæ•¸
            self.cap.set(cv2.CAP_PROP_FRAME_WIDTH, 640)
            self.cap.set(cv2.CAP_PROP_FRAME_HEIGHT, 480)
            self.cap.set(cv2.CAP_PROP_FPS, 30)
            
            self.is_streaming = True
            
            # å•Ÿå‹•æ”å½±æ©ŸåŸ·è¡Œç·’
            self.camera_thread = threading.Thread(target=self._camera_loop, daemon=True)
            self.camera_thread.start()
            
            return True, "æ”å½±æ©Ÿå•Ÿå‹•æˆåŠŸ"
        except Exception as e:
            return False, f"æ”å½±æ©Ÿå•Ÿå‹•å¤±æ•—: {str(e)}"
    
    def _camera_loop(self):
        """æ”å½±æ©Ÿä¸»å¾ªç’°"""
        while self.is_streaming and self.cap:
            ret, frame = self.cap.read()
            if not ret:
                continue
                
            display_frame = frame.copy()
            
            if self.detection_active:
                try:
                    count = self.process_contours(frame, display_frame)
                    self.current_count = count
                except Exception as e:
                    print(f"è™•ç†éŒ¯èª¤: {e}")
                    self.current_count = 0
            else:
                self.current_count = 0
                
            # æ›´æ–°æœ€æ–°å¹€
            with self.frame_lock:
                self.latest_frame = display_frame.copy()
                
            time.sleep(1/30)  # æ§åˆ¶å¹€ç‡
    
    def stop_camera(self):
        self.is_streaming = False
        self.detection_active = False
        if self.cap:
            self.cap.release()
            self.cap = None
        with self.frame_lock:
            self.latest_frame = None
        return True, "æ”å½±æ©Ÿå·²åœæ­¢"
    
    def get_frame_as_base64(self):
        """ç²å–ç•¶å‰å¹€çš„ base64 ç·¨ç¢¼"""
        with self.frame_lock:
            if self.latest_frame is None:
                return None
            frame = self.latest_frame.copy()
            
        # ç·¨ç¢¼ç‚º JPEG
        ret, buffer = cv2.imencode('.jpg', frame, [cv2.IMWRITE_JPEG_QUALITY, 80])
        if ret:
            # è½‰æ›ç‚º base64
            img_base64 = base64.b64encode(buffer).decode('utf-8')
            return f"data:image/jpeg;base64,{img_base64}"
        return None
    
    def process_contours(self, frame, display_frame):
        gray = cv2.cvtColor(frame, cv2.COLOR_BGR2GRAY)
        blur = cv2.GaussianBlur(gray, (7, 7), 0)
        
        if self.algorithm == "algorithm1":
            # ç®—æ³•ä¸€ï¼šOtsu äºŒå€¼åŒ–
            _, thresh = cv2.threshold(blur, 80, 255, cv2.THRESH_BINARY_INV + cv2.THRESH_OTSU)
            contours, _ = cv2.findContours(thresh, cv2.RETR_EXTERNAL, cv2.CHAIN_APPROX_SIMPLE)
        else:
            # ç®—æ³•äºŒï¼šCanny é‚Šç·£åµæ¸¬
            canny = cv2.Canny(blur, 100, 150, 3)
            dilated = cv2.dilate(canny, (1, 1), iterations=0)
            contours, _ = cv2.findContours(dilated.copy(), cv2.RETR_EXTERNAL, cv2.CHAIN_APPROX_NONE)
        
        count = len(contours)
        
        # ç•«å‡ºè¼ªå»“
        cv2.drawContours(display_frame, contours, -1, (0, 255, 0), 2)
        
        # é¡¯ç¤ºæ•¸é‡
        cv2.putText(display_frame, f"Count: {count}", (20, 50),
                   cv2.FONT_HERSHEY_SIMPLEX, 1.5, (0, 0, 255), 3, cv2.LINE_AA)
        
        return count

# å‰µå»ºæ”å½±æ©Ÿæ§åˆ¶å™¨å¯¦ä¾‹
camera_controller = CameraController()

@app.get("/")
async def root():
    return {"message": "è¼ªå»“åµæ¸¬ API æœå‹™é‹è¡Œä¸­"}

@app.post("/api/camera/start")
async def start_camera():
    success, message = camera_controller.start_camera()
    if success:
        return {"success": True, "message": message}
    else:
        raise HTTPException(status_code=400, detail=message)

@app.post("/api/camera/stop")
async def stop_camera():
    success, message = camera_controller.stop_camera()
    return {"success": success, "message": message}

@app.post("/api/detection/start")
async def start_detection():
    camera_controller.detection_active = True
    return {"success": True, "message": "é–‹å§‹è¼ªå»“åµæ¸¬"}

@app.post("/api/detection/stop")
async def stop_detection():
    camera_controller.detection_active = False
    return {"success": True, "message": "åœæ­¢è¼ªå»“åµæ¸¬"}

@app.post("/api/algorithm/change")
async def change_algorithm(request: AlgorithmRequest):
    camera_controller.algorithm = request.algorithm
    return {"success": True, "message": "ç®—æ³•å·²æ›´æ›"}

@app.get("/api/status")
async def get_status():
    timestamp = datetime.now().strftime('%H:%M:%S')
    return {
        "count": camera_controller.current_count,
        "timestamp": timestamp,
        "is_streaming": camera_controller.is_streaming,
        "detection_active": camera_controller.detection_active,
        "algorithm": camera_controller.algorithm
    }

@app.get("/api/video/frame")
async def get_video_frame():
    """ç²å–ç•¶å‰è¦–è¨Šå¹€"""
    frame_data = camera_controller.get_frame_as_base64()
    if frame_data:
        return {"frame": frame_data}
    else:
        raise HTTPException(status_code=404, detail="ç„¡æ³•ç²å–è¦–è¨Šå¹€")

if __name__ == "__main__":
    print("ğŸš€ å•Ÿå‹• FastAPI å¾Œç«¯æœå‹™")
    print("ğŸ“± API æ–‡æª”: http://localhost:8000/docs")
    print("ğŸŒ å±€åŸŸç¶²å­˜å–: http://[æ‚¨çš„IPåœ°å€]:8000")
    print("ğŸ’¡ æŒ‰ Ctrl+C åœæ­¢æœå‹™")
    
    uvicorn.run(
        "main:app", 
        host="0.0.0.0", 
        port=8000, 
        reload=True,
        log_level="info"
    )